# -*- coding: utf-8 -*-
"""drug-prediction-app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qfrhgE-_iiDOzWKtxFSY00IOW5OXxVyn
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Set the aesthetic style of the plots
sns.set()

# Load the dataset
data_path = '/kaggle/input/introds/Drug.csv'
data = pd.read_csv('/content/sample_data/Drug.csv')

# Display the first few entries of the dataset
print(data.head())

# 0. Display basic information about the dataset
data.info()

# 1. Summary Statistics
data.describe()

# 2. Missing Values Check
data.isnull().sum()

# Numerical Features Distribution
fig, ax = plt.subplots(1, 3, figsize=(24, 6))  # Adjust for 3 subplots
data['Age'].hist(ax=ax[0], bins=20, edgecolor='black')
ax[0].set_title('Age Distribution')
ax[0].set_xlabel('Age')
ax[0].set_ylabel('Frequency')

data['Na'].hist(ax=ax[1], bins=20, edgecolor='black')  # Plot for Sodium
ax[1].set_title('Sodium (Na) Level Distribution')
ax[1].set_xlabel('Sodium Level')
ax[1].set_ylabel('Frequency')

data['K'].hist(ax=ax[2], bins=20, edgecolor='black')  # Plot for Potassium
ax[2].set_title('Potassium (K) Level Distribution')
ax[2].set_xlabel('Potassium Level')
ax[2].set_ylabel('Frequency')

plt.tight_layout()


# Categorical Features Distribution
fig, ax = plt.subplots(2, 2, figsize=(16, 12))
sns.countplot(x='Sex', data=data, ax=ax[0, 0])
ax[0, 0].set_title('Sex Distribution')

sns.countplot(x='BP', data=data, ax=ax[0, 1])
ax[0, 1].set_title('Blood Pressure (BP) Distribution')

sns.countplot(x='Cholesterol', data=data, ax=ax[1, 0])
ax[1, 0].set_title('Cholesterol Distribution')

sns.countplot(x='Drug', data=data, ax=ax[1, 1])
ax[1, 1].set_title('Drug Type Distribution')

plt.tight_layout()

# 4. Correlation Analysis
# Calculating the correlation matrix for numerical features only
numerical_data = data[['Age', 'Na', 'K']]
correlation_matrix = numerical_data.corr()

# Creating a heatmap for the correlation matrix

plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, fmt=".2f", cmap='coolwarm', vmin=-1, vmax=1)
plt.title('Correlation Matrix for Numerical Features')
plt.show()

# 5. Feature vs. Target Analysis
fig, ax = plt.subplots(3, 1, figsize=(8, 18))

# Boxplot for Age vs Drug
sns.boxplot(x='Drug', y='Age', data=data, ax=ax[0])
ax[0].set_title('Age Distribution for Each Drug Type')

# Boxplot for Na vs Drug
sns.boxplot(x='Drug', y='Na', data=data, ax=ax[1])
ax[1].set_title('Sodium (Na) Level Distribution for Each Drug Type')

# Boxplot for K vs Drug
sns.boxplot(x='Drug', y='K', data=data, ax=ax[2])
ax[2].set_title('Potassium (K) Level Distribution for Each Drug Type')

plt.tight_layout()



from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# Defining the feature set and the target variable
X = data.drop('Drug', axis=1)
y = data['Drug']

# Identifying numerical and categorical features
numerical_features = ['Age', 'Na', 'K']
categorical_features = ['Sex', 'BP', 'Cholesterol']

# Splitting the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Defining a column transformer with one-hot encoding for categorical features and scaling for numerical features
preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(), categorical_features)
    ])

# Fitting the transformer on the training data and transforming both the training and test data
X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score

# Initialize the models
knn = KNeighborsClassifier()
log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter for convergence
decision_tree = DecisionTreeClassifier()
svm = SVC()

# Dictionary to store models and their respective accuracies
models = {
    'K-Nearest Neighbors': knn,
    'Logistic Regression': log_reg,
    'Decision Tree': decision_tree,
    'Support Vector Machine': svm
}

# Dictionary to store accuracies
accuracies = {}

# Train and evaluate each model
for model_name, model in models.items():
    # Train the model
    model.fit(X_train_processed, y_train)

    # Make predictions on the test set
    y_pred = model.predict(X_test_processed)

    # Calculate the accuracy
    accuracy = accuracy_score(y_test, y_pred)
    accuracies[model_name] = accuracy

accuracies

from sklearn.metrics import confusion_matrix, classification_report
from tabulate import tabulate
# Initializing a dictionary to store evaluation metrics
model_evaluation_metrics = {}

# Iterating over each model to evaluate
for model_name, model in models.items():
    # Predict on the test set
    y_pred = model.predict(X_test_processed)

    # Calculate confusion matrix and classification report
    conf_matrix = confusion_matrix(y_test, y_pred)
    classif_report = classification_report(y_test, y_pred)

    # Storing the results
    model_evaluation_metrics[model_name] = {
        'Confusion Matrix': conf_matrix,
        'Classification Report': classif_report
    }

    # Outputting the results for review
    print(f"{model_name} Evaluation Metrics:")
    print("Confusion Matrix:")
    print(tabulate(conf_matrix, headers=model.classes_, tablefmt='grid'))
    print("\nClassification Report:")
    print(classif_report)
    print("\n" + "="*60 + "\n")

!pip install pyngrok

!pip install streamlit pyngrok scikit-learn pandas joblib

from pyngrok import ngrok
ngrok.set_auth_token("ngrok config add-authtoken 35pMGDkRADs7LceBK5Nftvvfo9G_WWEW9NAXCHLj4397WuPL")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import pandas as pd
# import joblib
# from sklearn.model_selection import train_test_split
# from sklearn.preprocessing import StandardScaler, OneHotEncoder
# from sklearn.compose import ColumnTransformer
# from sklearn.pipeline import Pipeline
# from sklearn.linear_model import LogisticRegression
# 
# st.set_page_config(page_title="Drug Prescription Classifier", layout="centered")
# 
# st.title("üíä Drug Prescription Classification App")
# st.write("Upload your dataset or use the demo model to predict the drug type.")
# 
# # -----------------------------
# # Load / Train Model
# # -----------------------------
# 
# def load_sample_df():
#     return pd.DataFrame([
#         [23, 'F', 'HIGH', 'HIGH', 0.792535, 0.031258, 'drugY'],
#         [47, 'M', 'LOW', 'HIGH', 0.739309, 0.056468, 'drugC'],
#         [47, 'M', 'LOW', 'HIGH', 0.697269, 0.068944, 'drugC'],
#         [28, 'F', 'NORMAL', 'HIGH', 0.563682, 0.072289, 'drugX'],
#         [61, 'F', 'LOW', 'HIGH', 0.559294, 0.030998, 'drugY'],
#         [45, 'M', 'NORMAL', 'NORMAL', 0.700000, 0.050000, 'drugA']
#     ], columns=['Age','Sex','BP','Cholesterol','Na','K','Drug'])
# 
# 
# @st.cache_resource
# def train_model(df):
#     X = df[['Age','Sex','BP','Cholesterol','Na','K']]
#     y = df['Drug']
# 
#     numeric = ['Age','Na','K']
#     categorical = ['Sex','BP','Cholesterol']
# 
#     preprocessor = ColumnTransformer([
#     ("num", StandardScaler(), numeric),
#     ("cat", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical)
# ])
# 
# 
#     model = Pipeline([
#         ("pre", preprocessor),
#         ("clf", LogisticRegression(max_iter=2000, multi_class="multinomial"))
#     ])
# 
#     model.fit(X, y)
#     return model
# 
# 
# # -----------------------------
# # Upload Dataset
# # -----------------------------
# 
# uploaded_file = st.file_uploader("/content/sample_data/Drug.csv", type=['csv'])
# 
# if uploaded_file:
#     df = pd.read_csv(uploaded_file)
#     st.success("CSV Loaded Successfully!")
# else:
#     df = load_sample_df()
#     st.info("Using built-in sample dataset.")
# 
# model = train_model(df)
# 
# # -----------------------------
# # Prediction Form
# # -----------------------------
# 
# st.subheader("üß™ Enter Patient Information")
# 
# col1, col2 = st.columns(2)
# 
# with col1:
#     age = st.number_input("Age", min_value=1, max_value=120, value=45)
#     sex = st.selectbox("Sex", ["F", "M"])
#     bp = st.selectbox("Blood Pressure", ["LOW", "NORMAL", "HIGH"])
# 
# with col2:
#     cholesterol = st.selectbox("Cholesterol", ["HIGH", "NORMAL"])
#     na = st.number_input("Sodium (Na)", value=0.70, format="%.4f")
#     k = st.number_input("Potassium (K)", value=0.05, format="%.4f")
# 
# if st.button("üîç Predict Drug"):
#     input_df = pd.DataFrame([[age, sex, bp, cholesterol, na, k]],
#                             columns=['Age','Sex','BP','Cholesterol','Na','K'])
#     prediction = model.predict(input_df)[0]
#     st.success(f"üíä **Predicted Drug:** {prediction}")
# 
# st.markdown("---")
# st.write("Built with Streamlit ¬∑ Suitable for Google Colab üöÄ")
#

from pyngrok import ngrok
ngrok.set_auth_token("35pMGDkRADs7LceBK5Nftvvfo9G_WWEW9NAXCHLj4397WuPL")

import subprocess

# Kill previous tunnels if any
ngrok.kill()

# Start a new tunnel
public_url = ngrok.connect(8501)
print("üåê Public URL:", public_url)

# Start Streamlit app
subprocess.Popen(["streamlit", "run", "app.py"])

curl https://loca.lt/mytunnelpassword

!npm install -g localtunnel
!streamlit run app.py & sleep 5
!lt --port 8501 --print-requests

# ============================
# üöÄ COLAB STREAMLIT AUTO-LAUNCHER
# ============================

import subprocess, time, re, random

# Install LocalTunnel
print("Installing localtunnel...")
!npm install -g localtunnel > /dev/null

# Pick a free random port between 8501 and 8999
port = random.randint(8501, 8999)
print(f"Using port: {port}")

# Start Streamlit in the background
print("Starting Streamlit app...")
streamlit_cmd = f"streamlit run app.py --server.port {port} --server.address 0.0.0.0"
subprocess.Popen(streamlit_cmd.split(), stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)

# Wait for Streamlit to boot
time.sleep(5)

# Start localtunnel
print("Starting LocalTunnel...")
lt_cmd = f"lt --port {port}"
lt_output = subprocess.Popen(lt_cmd.split(), stdout=subprocess.PIPE, stderr=subprocess.PIPE)

# Read output to find the public URL
public_url = None
for _ in range(20):
    line = lt_output.stdout.readline().decode()
    if "https://" in line:
        public_url = line.strip()
        break

# Display result
if public_url:
    print("\nüéâ Your Streamlit app is live!")
    print("üëâ Public URL:", public_url)
else:
    print("\n‚ùå LocalTunnel failed to generate a URL.")
    print("Try running just: !lt --port", port)

import streamlit as st
import pandas as pd
import joblib
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression

st.set_page_config(page_title="Drug Prescription Classifier", layout="centered")

st.title("üíä Drug Prescription Classifier")
st.write("Upload your dataset or use the demo model to predict the drug type.")

# ------------------------------------------------------
# Load or sample dataset
# ------------------------------------------------------
def load_sample_df():
    return pd.DataFrame([
        [23, 'F', 'HIGH', 'HIGH', 0.792535, 0.031258, 'drugY'],
        [47, 'M', 'LOW', 'HIGH', 0.739309, 0.056468, 'drugC'],
        [47, 'M', 'LOW', 'HIGH', 0.697269, 0.068944, 'drugC'],
        [28, 'F', 'NORMAL', 'HIGH', 0.563682, 0.072289, 'drugX'],
        [61, 'F', 'LOW', 'HIGH', 0.559294, 0.030998, 'drugY'],
        [45, 'M', 'NORMAL', 'NORMAL', 0.700000, 0.050000, 'drugA']
    ], columns=['Age','Sex','BP','Cholesterol','Na','K','Drug'])

# ------------------------------------------------------
# Model training function
# ------------------------------------------------------
@st.cache_resource
def train_model(df):
    X = df[['Age','Sex','BP','Cholesterol','Na','K']]
    y = df['Drug']

    numeric = ['Age','Na','K']
    categorical = ['Sex','BP','Cholesterol']

    preprocessor = ColumnTransformer([
        ("num", StandardScaler(), numeric),
        ("cat", OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical)
    ])

    model = Pipeline([
        ("pre", preprocessor),
        ("clf", LogisticRegression(max_iter=2000, multi_class="multinomial"))
    ])

    model.fit(X, y)
    return model

# ------------------------------------------------------
# Upload dataset
# ------------------------------------------------------
uploaded = st.file_uploader("üìÇ Upload CSV (optional)", type=['csv'])

if uploaded:
    df = pd.read_csv(uploaded)
    st.success("Dataset uploaded successfully!")
else:
    df = load_sample_df()
    st.info("Using built-in sample dataset.")

model = train_model(df)

# ------------------------------------------------------
# Prediction form
# ------------------------------------------------------
st.subheader("üß™ Enter Patient Information")

col1, col2 = st.columns(2)

with col1:
    age = st.number_input("Age", min_value=1, max_value=120, value=45)
    sex = st.selectbox("Sex", ["F", "M"])
    bp = st.selectbox("Blood Pressure", ["LOW", "NORMAL", "HIGH"])

with col2:
    cholesterol = st.selectbox("Cholesterol", ["HIGH", "NORMAL"])
    na = st.number_input("Sodium (Na)", value=0.70, format="%.4f")
    k = st.number_input("Potassium (K)", value=0.05, format="%.4f")

if st.button("üîç Predict Drug"):
    input_df = pd.DataFrame([[age, sex, bp, cholesterol, na, k]],
                            columns=['Age','Sex','BP','Cholesterol','Na','K'])
    prediction = model.predict(input_df)[0]
    st.success(f"üíä **Predicted Drug:** {prediction}")

st.markdown("---")
st.write("Built with Streamlit ¬∑ Hosted on Streamlit Cloud üöÄ")

